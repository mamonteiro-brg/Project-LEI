{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OFFSIDES dataset loader.\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import deepchem\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def load_offsides(featurizer='ECFP', split='index', reload=True, K=4):\n",
    "  logger.info(\"About to load ofssides dataset.\")\n",
    "  data_dir = deepchem.utils.get_data_dir()\n",
    "  if reload:\n",
    "    save_dir = os.path.join(data_dir, \"offsides/\" + featurizer + \"/\" + str(split))\n",
    "\n",
    "  dataset_file = os.path.join(\"/home/mamonteiro/source-code/Project-LEI/sider+offsides/\", \"sider+offsides_combined.csv.gz\")\n",
    "\n",
    "\n",
    "  dataset = deepchem.utils.save.load_from_disk(dataset_file)\n",
    "  logger.info(\"Columns of dataset: %s\" % str(dataset.columns.values))\n",
    "  logger.info(\"Number of examples in dataset: %s\" % str(dataset.shape[0]))\n",
    "  OFFSIDES_tasks = dataset.columns.values[1:].tolist()\n",
    "\n",
    "  if reload:\n",
    "    loaded, all_dataset, transformers = deepchem.utils.save.load_dataset_from_disk(\n",
    "        save_dir)\n",
    "    if loaded:\n",
    "      return OFFSIDES_tasks, all_dataset, transformers\n",
    "\n",
    "  # Featurize OFFSIDES dataset\n",
    "  logger.info(\"About to featurize OFFSIDES dataset.\")\n",
    "  if featurizer == 'ECFP':\n",
    "    featurizer = deepchem.feat.CircularFingerprint(size=1024)\n",
    "  elif featurizer == 'GraphConv':\n",
    "    featurizer = deepchem.feat.ConvMolFeaturizer()\n",
    "  elif featurizer == 'Weave':\n",
    "    featurizer = deepchem.feat.WeaveFeaturizer()\n",
    "  elif featurizer == 'Raw':\n",
    "    featurizer = deepchem.feat.RawFeaturizer()\n",
    "\n",
    "  logger.info(\"OFFSIDES tasks: %s\" % str(OFFSIDES_tasks))\n",
    "  logger.info(\"%d tasks in total\" % len(OFFSIDES_tasks))\n",
    "\n",
    "  loader = deepchem.data.CSVLoader(\n",
    "      tasks=OFFSIDES_tasks, smiles_field=\"smiles\", featurizer=featurizer)\n",
    "  dataset = loader.featurize(dataset_file)\n",
    "  logger.info(\"%d datapoints in OFFSIDES dataset\" % len(dataset))\n",
    "\n",
    "  # Initialize transformers\n",
    "  transformers = [\n",
    "      deepchem.trans.BalancingTransformer(transform_w=True, dataset=dataset)\n",
    "  ]\n",
    "  logger.info(\"About to transform data\")\n",
    "  for transformer in transformers:\n",
    "    dataset = transformer.transform(dataset)\n",
    "\n",
    "  if split == None:\n",
    "    return OFFSIDES_tasks, (dataset, None, None), transformers\n",
    "\n",
    "  splitters = {\n",
    "      'index': deepchem.splits.IndexSplitter(),\n",
    "      'random': deepchem.splits.RandomSplitter(),\n",
    "      'scaffold': deepchem.splits.ScaffoldSplitter(),\n",
    "      'task': deepchem.splits.TaskSplitter()\n",
    "  }\n",
    "  splitter = splitters[split]\n",
    "  if split == 'task':\n",
    "    fold_datasets = splitter.k_fold_split(dataset, K)\n",
    "    all_dataset = fold_datasets\n",
    "  else:\n",
    "    train, valid, test = splitter.train_valid_test_split(dataset)\n",
    "    if reload:\n",
    "      deepchem.utils.save.save_dataset_to_disk(save_dir, train, valid, test,\n",
    "                                               transformers)\n",
    "    all_dataset = (train, valid, test)\n",
    "  return OFFSIDES_tasks, all_dataset, transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "offsides_tasks, offsides_datasets, transformers = load_offsides(featurizer='GraphConv',reload=True)\n",
    "train_dataset, valid_dataset, test_dataset = offsides_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.CircularFingerprint(size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dc.data.CSVLoader(\n",
    "      tasks=offsides_tasks, smiles_field=\"smiles\",\n",
    "      featurizer=featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from sider+offsides_combined.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "TIMING: featurizing shard 0 took 2.259 s\n",
      "TIMING: dataset construction took 2.321 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "dataset = loader.featurize('sider+offsides_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = train_dataset.y.shape[0]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\"activation\": [\"relu\",\"sigmoid\",\"tahn\"],\n",
    "               \"optimizer\": [\"Adam\",\"RMSprop\"],\n",
    "               \"momentum\": [.9],\n",
    "               \"penalty\": [0.]\n",
    "              }\n",
    "n_features = train_dataset.y.shape[0]\n",
    "def model_builder(model_params, model_dir):\n",
    "    model = dc.models.MultitaskClassifier(\n",
    "    len(offsides_tasks), n_features, **model_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1/6\n",
      "hyperparameters: {'activation': 'relu', 'optimizer': 'Adam', 'momentum': 0.9, 'penalty': 0.0}\n",
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/deepchem/models/tensorgraph/tensor_graph.py\", line 1393, in _enqueue_batch\n",
      "    sess.run(tg.input_queue.out_tensor, feed_dict=enq)\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1121, in _run\n",
      "    np_val = np.asarray(subfeed_val, dtype=subfeed_dtype)\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/numpy/core/numeric.py\", line 538, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "TypeError: float() argument must be a string or a number, not 'ConvMol'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
    "optimizer = dc.hyper.HyperparamOpt(model_builder)\n",
    "best_dnn, best_hyperparams, all_results = optimizer.hyperparam_search(params_dict, train_dataset, valid_dataset, [], metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultitaskClassifier(activation_fns=None, bias_init_consts=None, dropouts=None,\n",
       "                    layer_sizes=None, n_classes=2, n_features=1024, n_tasks=27,\n",
       "                    weight_decay_penalty=None, weight_decay_penalty_type=None,\n",
       "                    weight_init_stddevs=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('relu', 'Adam', 0.9, 0.0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('relu', 0.9, 0.0)\": 0.673746852484698,\n",
       " \"('sigmoid', 0.9, 0.0)\": 0.677523700567962,\n",
       " \"('tahn', 0.9, 0.0)\": 0.6779358768268917}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_builder(params_dict,params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154.36382479691386"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=best_dnn.fit(train_dataset,**params_dict,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.999376477978126, 0.9997829797788218, 1.0, 0.999951157565693, 0.9999160991017668, 0.9995059613991173, 0.9998969201534545, 0.9980603916457189, 0.9999344044697566, 0.9998678200138943, 0.9997858498865583, 0.9999026407536533, 0.9998593158487091, 0.996823499074009, 0.9999209803850739, 0.9999265397273155, 0.9998704998704999, 0.9995396227942367, 0.9998608730494402, 0.9998500336910612, 0.9999192269834472, 0.9995410158848416, 0.9986063565108405, 0.9999275898194367, 0.9999651171329955, 0.9999608664175161, 0.9998507089588513]\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(train_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.6904457973291438, 0.5733415508740476, nan, 0.613184584178499, 0.6409558378705384, 0.6237373737373737, 0.8082706766917294, 0.7155797101449275, 0.5750784401613627, 0.6958137715179968, 0.6271739130434784, 0.5875739644970415, 0.7090579710144927, 0.6139122315592904, 0.6487577639751553, 0.6811244979919678, 0.6596692111959288, 0.5900590551181103, 0.6015070921985816, 0.6687883074021688, 0.6182038834951455, 0.6120430107526882, 0.6736842105263159, 0.676957223567393, 0.6353225806451612, 0.7947658402203857, 0.5948581560283688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/deepchem/metrics/__init__.py:368: UserWarning: Error calculating metric mean-roc_auc_score: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\"Error calculating metric %s: %s\" % (self.name, e))\n"
     ]
    }
   ],
   "source": [
    "valid_scores = model.evaluate(valid_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.67573385518591, 0.6939263510282161, 0.3279761904761904, 0.596551724137931, 0.7220625798212005, 0.5354109274563821, 0.6129476584022038, 0.5577673692427791, 0.6051423324150597, 0.5634050880626224, 0.6781553398058253, 0.6484444444444445, 0.5826612903225807, 0.5734295415959254, 0.6637790697674419, 0.6391397849462366, 0.765339966832504, 0.5323004201680672, 0.7463592233009708, 0.632233381157341, 0.6519742883379247, 0.611111111111111, 0.4527671755725191, 0.598995983935743, 0.6976226660877117, 0.596483942414175, 0.6470828233374133]\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(test_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean-roc_auc_score': 0.9996075166257347}\n",
      "{'mean-roc_auc_score': 0.6511487175283575}\n",
      "{'mean-roc_auc_score': 0.6151409084950529}\n"
     ]
    }
   ],
   "source": [
    "print(train_scores)\n",
    "print(valid_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
