{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OFFSIDES dataset loader.\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import deepchem\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def load_offsides(featurizer='ECFP', split='index', reload=True, K=4):\n",
    "  logger.info(\"About to load ofssides dataset.\")\n",
    "  data_dir = deepchem.utils.get_data_dir()\n",
    "  if reload:\n",
    "    save_dir = os.path.join(data_dir, \"offsides/\" + featurizer + \"/\" + str(split))\n",
    "\n",
    "  dataset_file = os.path.join(\"/home/mamonteiro/source-code/Project-LEI/sider+offsides/\", \"sider+offsides_combined.csv.gz\")\n",
    "\n",
    "\n",
    "  dataset = deepchem.utils.save.load_from_disk(dataset_file)\n",
    "  logger.info(\"Columns of dataset: %s\" % str(dataset.columns.values))\n",
    "  logger.info(\"Number of examples in dataset: %s\" % str(dataset.shape[0]))\n",
    "  OFFSIDES_tasks = dataset.columns.values[1:].tolist()\n",
    "\n",
    "  if reload:\n",
    "    loaded, all_dataset, transformers = deepchem.utils.save.load_dataset_from_disk(\n",
    "        save_dir)\n",
    "    if loaded:\n",
    "      return OFFSIDES_tasks, all_dataset, transformers\n",
    "\n",
    "  # Featurize OFFSIDES dataset\n",
    "  logger.info(\"About to featurize OFFSIDES dataset.\")\n",
    "  if featurizer == 'ECFP':\n",
    "    featurizer = deepchem.feat.CircularFingerprint(size=1024)\n",
    "  elif featurizer == 'GraphConv':\n",
    "    featurizer = deepchem.feat.ConvMolFeaturizer()\n",
    "  elif featurizer == 'Weave':\n",
    "    featurizer = deepchem.feat.WeaveFeaturizer()\n",
    "  elif featurizer == 'Raw':\n",
    "    featurizer = deepchem.feat.RawFeaturizer()\n",
    "\n",
    "  logger.info(\"OFFSIDES tasks: %s\" % str(OFFSIDES_tasks))\n",
    "  logger.info(\"%d tasks in total\" % len(OFFSIDES_tasks))\n",
    "\n",
    "  loader = deepchem.data.CSVLoader(\n",
    "      tasks=OFFSIDES_tasks, smiles_field=\"smiles\", featurizer=featurizer)\n",
    "  dataset = loader.featurize(dataset_file)\n",
    "  logger.info(\"%d datapoints in OFFSIDES dataset\" % len(dataset))\n",
    "\n",
    "  # Initialize transformers\n",
    "  transformers = [\n",
    "      deepchem.trans.BalancingTransformer(transform_w=True, dataset=dataset)\n",
    "  ]\n",
    "  logger.info(\"About to transform data\")\n",
    "  for transformer in transformers:\n",
    "    dataset = transformer.transform(dataset)\n",
    "\n",
    "  if split == None:\n",
    "    return OFFSIDES_tasks, (dataset, None, None), transformers\n",
    "\n",
    "  splitters = {\n",
    "      'index': deepchem.splits.IndexSplitter(),\n",
    "      'random': deepchem.splits.RandomSplitter(),\n",
    "      'scaffold': deepchem.splits.ScaffoldSplitter(),\n",
    "      'task': deepchem.splits.TaskSplitter()\n",
    "  }\n",
    "  splitter = splitters[split]\n",
    "  if split == 'task':\n",
    "    fold_datasets = splitter.k_fold_split(dataset, K)\n",
    "    all_dataset = fold_datasets\n",
    "  else:\n",
    "    train, valid, test = splitter.train_valid_test_split(dataset)\n",
    "    if reload:\n",
    "      deepchem.utils.save.save_dataset_to_disk(save_dir, train, valid, test,\n",
    "                                               transformers)\n",
    "    all_dataset = (train, valid, test)\n",
    "  return OFFSIDES_tasks, all_dataset, transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "offsides_tasks, offsides_datasets, transformers = load_offsides(featurizer='GraphConv',reload=True)\n",
    "train_dataset, valid_dataset, test_dataset = offsides_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.CircularFingerprint(size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dc.data.CSVLoader(\n",
    "      tasks=offsides_tasks, smiles_field=\"smiles\",\n",
    "      featurizer=featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loader.featurize('sider+offsides_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 27)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 27)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = train_dataset.y.shape[0]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\"activation\": [\"relu\",\"sigmoid\",\"tahn\"],\n",
    "               \"optimizer\": [\"Adam\",\"RMSprop\"],\n",
    "               \"momentum\": [.9],\n",
    "               \"penalty\": [0.]\n",
    "              }\n",
    "n_features = train_dataset.y.shape[0]\n",
    "def model_builder(model_params, model_dir):\n",
    "    model = dc.models.MultitaskClassifier(\n",
    "    len(offsides_tasks), n_features, **model_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1/6\n",
      "hyperparameters: {'activation': 'relu', 'optimizer': 'Adam', 'momentum': 0.9, 'penalty': 0.0}\n",
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/deepchem/models/tensorgraph/tensor_graph.py\", line 1393, in _enqueue_batch\n",
      "    sess.run(tg.input_queue.out_tensor, feed_dict=enq)\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1121, in _run\n",
      "    np_val = np.asarray(subfeed_val, dtype=subfeed_dtype)\n",
      "  File \"/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/numpy/core/numeric.py\", line 538, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "TypeError: float() argument must be a string or a number, not 'ConvMol'\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2d19e44a6a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHyperparamOpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_builder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_dnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_hyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/lei/lib/python3.6/site-packages/deepchem/hyper/grid_search.py\u001b[0m in \u001b[0;36mhyperparam_search\u001b[0;34m(self, params_dict, train_dataset, valid_dataset, output_transformers, metric, use_max, logdir)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lei/lib/python3.6/site-packages/deepchem/models/tensorgraph/tensor_graph.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, submodel, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         self.default_generator(\n\u001b[1;32m    153\u001b[0m             dataset, epochs=nb_epoch, deterministic=deterministic),\n\u001b[0;32m--> 154\u001b[0;31m         max_checkpoints_to_keep, checkpoint_interval, restore, submodel)\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m   def fit_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/lei/lib/python3.6/site-packages/deepchem/models/tensorgraph/tensor_graph.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, feed_dict_generator, max_checkpoints_to_keep, checkpoint_interval, restore, submodel)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfinal_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfinal_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
    "optimizer = dc.hyper.HyperparamOpt(model_builder)\n",
    "best_dnn, best_hyperparams, all_results = optimizer.hyperparam_search(params_dict, train_dataset, valid_dataset, [], metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultitaskClassifier(activation_fns=None, bias_init_consts=None, dropouts=None,\n",
       "                    layer_sizes=None, n_classes=2, n_features=1024, n_tasks=27,\n",
       "                    weight_decay_penalty=None, weight_decay_penalty_type=None,\n",
       "                    weight_init_stddevs=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('relu', 'Adam', 0.9, 0.0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('relu', 0.9, 0.0)\": 0.673746852484698,\n",
       " \"('sigmoid', 0.9, 0.0)\": 0.677523700567962,\n",
       " \"('tahn', 0.9, 0.0)\": 0.6779358768268917}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_builder(params_dict,params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154.36382479691386"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=best_dnn.fit(train_dataset,**params_dict,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.999376477978126, 0.9997829797788218, 1.0, 0.999951157565693, 0.9999160991017668, 0.9995059613991173, 0.9998969201534545, 0.9980603916457189, 0.9999344044697566, 0.9998678200138943, 0.9997858498865583, 0.9999026407536533, 0.9998593158487091, 0.996823499074009, 0.9999209803850739, 0.9999265397273155, 0.9998704998704999, 0.9995396227942367, 0.9998608730494402, 0.9998500336910612, 0.9999192269834472, 0.9995410158848416, 0.9986063565108405, 0.9999275898194367, 0.9999651171329955, 0.9999608664175161, 0.9998507089588513]\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(train_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.6904457973291438, 0.5733415508740476, nan, 0.613184584178499, 0.6409558378705384, 0.6237373737373737, 0.8082706766917294, 0.7155797101449275, 0.5750784401613627, 0.6958137715179968, 0.6271739130434784, 0.5875739644970415, 0.7090579710144927, 0.6139122315592904, 0.6487577639751553, 0.6811244979919678, 0.6596692111959288, 0.5900590551181103, 0.6015070921985816, 0.6687883074021688, 0.6182038834951455, 0.6120430107526882, 0.6736842105263159, 0.676957223567393, 0.6353225806451612, 0.7947658402203857, 0.5948581560283688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/deepchem/metrics/__init__.py:368: UserWarning: Error calculating metric mean-roc_auc_score: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\"Error calculating metric %s: %s\" % (self.name, e))\n"
     ]
    }
   ],
   "source": [
    "valid_scores = model.evaluate(valid_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.67573385518591, 0.6939263510282161, 0.3279761904761904, 0.596551724137931, 0.7220625798212005, 0.5354109274563821, 0.6129476584022038, 0.5577673692427791, 0.6051423324150597, 0.5634050880626224, 0.6781553398058253, 0.6484444444444445, 0.5826612903225807, 0.5734295415959254, 0.6637790697674419, 0.6391397849462366, 0.765339966832504, 0.5323004201680672, 0.7463592233009708, 0.632233381157341, 0.6519742883379247, 0.611111111111111, 0.4527671755725191, 0.598995983935743, 0.6976226660877117, 0.596483942414175, 0.6470828233374133]\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(test_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean-roc_auc_score': 0.9996075166257347}\n",
      "{'mean-roc_auc_score': 0.6511487175283575}\n",
      "{'mean-roc_auc_score': 0.6151409084950529}\n"
     ]
    }
   ],
   "source": [
    "print(train_scores)\n",
    "print(valid_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
