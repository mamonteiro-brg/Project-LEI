{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Convolutions For SIDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Featurization=ConvMolFeaturizer\n",
    "\n",
    "É utilizado com modelos GraphConvModel.\n",
    "\n",
    "Alternativamente, também implementamos este modelo (GraphConvModel) usando layers do TensorGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc\n",
    "from deepchem.models.tensorgraph.models.graph_models import GraphConvModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SIDER Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All MoleculeNet datasets are split into training, validation and test subsets following a 80/10/10 ratio. \n",
    "\n",
    "Different  splittings are recommended depending on each dataset's contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "sider_tasks, sider_datasets, transformers = dc.molnet.load_sider(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = sider_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sider_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hepatobiliary disorders',\n",
       " 'Metabolism and nutrition disorders',\n",
       " 'Product issues',\n",
       " 'Eye disorders',\n",
       " 'Investigations',\n",
       " 'Musculoskeletal and connective tissue disorders',\n",
       " 'Gastrointestinal disorders',\n",
       " 'Social circumstances',\n",
       " 'Immune system disorders',\n",
       " 'Reproductive system and breast disorders',\n",
       " 'Neoplasms benign, malignant and unspecified (incl cysts and polyps)',\n",
       " 'General disorders and administration site conditions',\n",
       " 'Endocrine disorders',\n",
       " 'Surgical and medical procedures',\n",
       " 'Vascular disorders',\n",
       " 'Blood and lymphatic system disorders',\n",
       " 'Skin and subcutaneous tissue disorders',\n",
       " 'Congenital, familial and genetic disorders',\n",
       " 'Infections and infestations',\n",
       " 'Respiratory, thoracic and mediastinal disorders',\n",
       " 'Psychiatric disorders',\n",
       " 'Renal and urinary disorders',\n",
       " 'Pregnancy, puerperium and perinatal conditions',\n",
       " 'Ear and labyrinth disorders',\n",
       " 'Cardiac disorders',\n",
       " 'Nervous system disorders',\n",
       " 'Injury, poisoning and procedural complications']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sider_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different classification and regress metrics are recommended based on previous works and dataset's contents:\n",
    "          ROC-AUC:  Area Under Curve of Receiver Operating Characteristics\n",
    "          PRC-AUC:  Area Under Curve of Precision Recall Curve\n",
    "          RMSE: Root-Mean-Square Error\n",
    "          MAE: Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:317: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:317: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 828.177108\n",
      "Epoch 1 loss: 802.151752\n",
      "Epoch 2 loss: 789.594849\n",
      "Epoch 3 loss: 770.671883\n",
      "Epoch 4 loss: 759.342407\n",
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_management.py:624: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_management.py:624: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 759.136705\n",
      "Epoch 6 loss: 744.528864\n",
      "Epoch 7 loss: 728.219039\n",
      "Epoch 8 loss: 719.593187\n",
      "Epoch 9 loss: 712.222601\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "losses = []\n",
    "\n",
    "model = GraphConvModel(\n",
    "    len(sider_tasks), batch_size=50, mode='classification')\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # Set nb_epoch=10 for better results.\n",
    "    loss = model.fit(train_dataset, nb_epoch=1)\n",
    "    print(\"Epoch %d loss: %f\" % (i, loss))\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "\n",
    "plot.figure(figsize=(10,7))\n",
    "plot.ylabel(\"Loss\")\n",
    "plot.xlabel(\"Epoch\")\n",
    "x = range(num_epochs)\n",
    "y = losses\n",
    "plot.scatter(x, y)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.7454158964879851, 0.7048954733359369, 0.9643962848297214, 0.7099743588053444, 0.7353541969917516, 0.7097031772878722, 0.7870208805909382, 0.7646466928147524, 0.6464145972959361, 0.7595839177185599, 0.7432386853870891, 0.7108224877320247, 0.7510797363170258, 0.7730334432406971, 0.7032080718057405, 0.7550073460578323, 0.7766246602421547, 0.7144959566025416, 0.6989220842191639, 0.7013563776025873, 0.7133301298919219, 0.733575789930266, 0.7964975179260894, 0.7014757602074442, 0.7197216714401116, 0.8108054226475279, 0.6457487221991988]\n",
      "Training ROC-AUC Score: 0.739865\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(\n",
    "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
    "print(\"Training ROC-AUC Score: %f\" % train_scores[\"mean-roc_auc_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.7023338607594937, 0.5304101838755304, 0.5140845070422535, 0.5763694522191123, 0.6645379413974455, 0.4977443609022556, 0.6406423034330011, 0.6132203389830508, 0.5398936170212766, 0.5848091302636758, 0.5554617117117118, 0.38154269972451793, 0.6225490196078431, 0.6495934959349594, 0.5693215339233039, 0.6304347826086956, 0.6387795275590551, 0.6612021857923498, 0.5718604651162791, 0.5658391797085807, 0.5448837209302326, 0.6137646547980895, 0.7175572519083969, 0.605875152998776, 0.6337965038099507, 0.6895674300254453, 0.5127877237851662]\n",
      "Validation ROC-AUC Score: 0.593662\n"
     ]
    }
   ],
   "source": [
    "valid_scores = model.evaluate(valid_dataset, [metric], transformers)\n",
    "print(\"Validation ROC-AUC Score: %f\" % valid_scores[\"mean-roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 847.572515\n",
      "Epoch 1 loss: 808.224588\n",
      "Epoch 2 loss: 791.289381\n",
      "Epoch 3 loss: 776.450479\n",
      "Epoch 4 loss: 767.277516\n",
      "Epoch 5 loss: 764.353805\n",
      "Epoch 6 loss: 749.929250\n",
      "Epoch 7 loss: 733.003933\n",
      "Epoch 8 loss: 719.862713\n",
      "Epoch 9 loss: 710.481849\n",
      "Epoch 10 loss: 695.807742\n",
      "Epoch 11 loss: 686.610951\n",
      "Epoch 12 loss: 685.314363\n",
      "Epoch 13 loss: 672.649579\n",
      "Epoch 14 loss: 661.392732\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "losses = []\n",
    "\n",
    "model = GraphConvModel(\n",
    "    len(sider_tasks), batch_size=50, mode='classification')\n",
    "# Set nb_epoch=10 for better results.\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # Set nb_epoch=10 for better results.\n",
    "    loss = model.fit(train_dataset, nb_epoch=1)\n",
    "    print(\"Epoch %d loss: %f\" % (i, loss))\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.7898890942698706, 0.7122219192819825, 0.9917909747631111, 0.736620767390201, 0.7762178554099952, 0.7092531159488673, 0.8025601504488261, 0.8030320142924616, 0.73688064153721, 0.7971691149331956, 0.7515962036238135, 0.7763050280918853, 0.7999688497124913, 0.7754415920866697, 0.7287494678875817, 0.7845378484501768, 0.7934272300469483, 0.7755437239439449, 0.7032785050911938, 0.7176409945421468, 0.7569846463629499, 0.7456474592105702, 0.8488692774407061, 0.7316346076855325, 0.7477454652272895, 0.8324960127591707, 0.708001795828153]\n",
      "Training ROC-AUC Score: 0.771611\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(\n",
    "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
    "print(\"Training ROC-AUC Score: %f\" % train_scores[\"mean-roc_auc_score\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.6821598101265822, 0.5603488920320603, 0.5, 0.59656137544982, 0.7175056348610067, 0.5205513784461153, 0.5913621262458472, 0.584406779661017, 0.5323581560283688, 0.6265249901613539, 0.5788288288288288, 0.5296143250688705, 0.5808823529411764, 0.5691056910569106, 0.5283185840707965, 0.684670551322277, 0.578248031496063, 0.6295862607338018, 0.5806976744186046, 0.617107393416082, 0.5739534883720931, 0.6191923577941816, 0.6908396946564885, 0.584251325989392, 0.6443298969072165, 0.7493638676844783, 0.5566922421142371]\n",
      "Validation ROC-AUC Score: 0.600276\n"
     ]
    }
   ],
   "source": [
    "valid_scores = model.evaluate(valid_dataset, [metric], transformers)\n",
    "print(\"Validation ROC-AUC Score: %f\" % valid_scores[\"mean-roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparameters permitidos pelo deepchem e os valores que são utilizados por defeito"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# hps['graphconv'] = {\n",
    "    'batch_size': 64,\n",
    "    'nb_epoch': 40,\n",
    "    'learning_rate': 0.0005,\n",
    "    'n_filters': 64,\n",
    "    'n_fully_connected_nodes': 128,\n",
    "    'seed': 123\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batch_size = hyper_parameters['batch_size']\n",
    "nb_epoch = hyper_parameters['nb_epoch']\n",
    "learning_rate = hyper_parameters['learning_rate']\n",
    "n_filters = hyper_parameters['n_filters']\n",
    "n_fully_connected_nodes = hyper_parameters['n_fully_connected_nodes']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\"nb_epoch\": [10],\n",
    "              'learning_rate': [0.0005,0.5,0.75,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(train_dataset)\n",
    "\n",
    "def model_builder(model_params, model_dir):\n",
    "    model = GraphConvModel(\n",
    "            len(sider_tasks), batch_size=50, mode='classification',**model_params)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1/4\n",
      "hyperparameters: {'nb_epoch': 10, 'learning_rate': 0.0005}\n",
      "computed_metrics: [0.6526898734177216, 0.5238095238095238, 0.8450704225352113, 0.5985605757696921, 0.6389932381667919, 0.47794486215538845, 0.55703211517165, 0.5542372881355933, 0.6779698581560284, 0.6168831168831169, 0.5253378378378379, 0.6163911845730028, 0.671218487394958, 0.6178861788617886, 0.5876106194690266, 0.6441057821604661, 0.6663385826771653, 0.6530054644808744, 0.5702325581395349, 0.4622234214786832, 0.5906976744186045, 0.5388623534520192, 0.5954198473282443, 0.47674418604651164, 0.6241595696996862, 0.688295165394402, 0.5846121057118498]\n",
      "Model 1/4, Metric mean-roc_auc_score, Validation set 0: 0.602086\n",
      "\tbest_validation_score so far: 0.602086\n",
      "Fitting model 2/4\n",
      "hyperparameters: {'nb_epoch': 10, 'learning_rate': 0.5}\n",
      "computed_metrics: [0.5636372626582278, 0.5604667609618105, 0.630281690140845, 0.5015493802479009, 0.5632982719759579, 0.481140350877193, 0.5239479512735327, 0.5344915254237288, 0.4342863475177305, 0.5193329397874853, 0.5499718468468469, 0.5385674931129476, 0.5502450980392157, 0.4416666666666667, 0.5707964601769913, 0.6127857463021067, 0.5490895669291338, 0.4731654957064793, 0.4907558139534884, 0.5119400971397734, 0.4743604651162791, 0.6113221884498481, 0.5486641221374046, 0.5015299877600978, 0.5907664724338861, 0.6025763358778626, 0.4688832054560955]\n",
      "Model 2/4, Metric mean-roc_auc_score, Validation set 1: 0.533316\n",
      "\tbest_validation_score so far: 0.602086\n",
      "Fitting model 3/4\n",
      "hyperparameters: {'nb_epoch': 10, 'learning_rate': 0.75}\n",
      "computed_metrics: [0.5176028481012658, 0.5021805752003772, 0.5, 0.5306877249100359, 0.5681818181818181, 0.49360902255639094, 0.570874861572536, 0.4821186440677966, 0.49734042553191493, 0.5357634789452972, 0.4827561936936937, 0.4850206611570248, 0.645483193277311, 0.5077235772357723, 0.4976401179941003, 0.5649932765575976, 0.5418307086614174, 0.49746291959406713, 0.5388372093023256, 0.475512682137075, 0.5000581395348838, 0.5932479374728615, 0.5, 0.49750101999184004, 0.5615194979829672, 0.6838422391857506, 0.5427323103154305]\n",
      "Model 3/4, Metric mean-roc_auc_score, Validation set 2: 0.530167\n",
      "\tbest_validation_score so far: 0.602086\n",
      "Fitting model 4/4\n",
      "hyperparameters: {'nb_epoch': 10, 'learning_rate': 1}\n",
      "computed_metrics: [0.6281645569620253, 0.5133781235266384, 0.5352112676056338, 0.5182926829268293, 0.5019722013523666, 0.5776315789473684, 0.5474806201550388, 0.6155084745762712, 0.5216090425531915, 0.5433884297520661, 0.5368102477477477, 0.6494490358126721, 0.5001750700280112, 0.6151422764227643, 0.5172566371681416, 0.6430972658000897, 0.5925196850393701, 0.5181498829039812, 0.5484883720930234, 0.5116028062601188, 0.5144767441860465, 0.4991315675206253, 0.5206743002544529, 0.5563545491636066, 0.5877969520394443, 0.6033715012722647, 0.5028772378516624]\n",
      "Model 4/4, Metric mean-roc_auc_score, Validation set 3: 0.552593\n",
      "\tbest_validation_score so far: 0.602086\n",
      "computed_metrics: [0.7376216882316697, 0.6772679375419102, 0.9838164931044189, 0.6830478086336342, 0.7300218340611353, 0.7045374530883644, 0.7662856976676555, 0.7514374602131548, 0.6804129702088095, 0.7486097783026993, 0.725947133108479, 0.6594925680961525, 0.7369568694802954, 0.7212199717381065, 0.6634468204584771, 0.7320265368213024, 0.7118729923400051, 0.7277613139786026, 0.6516206034836447, 0.6280513442490399, 0.696126886788855, 0.7120883520736713, 0.7959919102776245, 0.679659638943809, 0.7070619446280385, 0.772627591706539, 0.6258288437629507]\n",
      "Best hyperparameters: (10, 0.0005)\n",
      "train_score: 0.718920\n",
      "validation_score: 0.602086\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
    "optimizer = dc.hyper.HyperparamOpt(model_builder)\n",
    "best_dnn, best_hyperparams, all_results = optimizer.hyperparam_search(\n",
    "   params_dict, train_dataset, valid_dataset, [], metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphConvModel(dense_layer_size=128, dropout=[0.0, 0.0, 0.0],\n",
       "               graph_conv_layers=[64, 64], mode='classification', n_classes=2,\n",
       "               n_tasks=27, number_atom_features=75, uncertainty=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 0.0005)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(10, 0.0005)': 0.6020863664194583,\n",
       " '(10, 0.5)': 0.5333155386285013,\n",
       " '(10, 0.75)': 0.530167447524502,\n",
       " '(10, 1)': 0.5525930040711647}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Implementation GraphConvModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorGraph - Simplicity is Beauty\n",
    "TensorGraph is a simple, lean, and clean framework on TensorFlow for building any imaginable models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s going on under the hood? \n",
    "\n",
    "Now we will build GraphConvModel ourselves.\n",
    "\n",
    "The first step is to create a TensorGraph object. \n",
    "This object will hold the “computational graph” that defines the computation that a graph convolutional network will perform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.tensor_graph import TensorGraph\n",
    "from deepchem.models.tensorgraph.layers import Dense, GraphConv, BatchNorm\n",
    "from deepchem.models.tensorgraph.layers import GraphPool, GraphGather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = TensorGraph(use_queue=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.layers import Feature\n",
    "\n",
    "atom_features = Feature(shape=(None, 75))\n",
    "degree_slice = Feature(shape=(None, 2), dtype=tf.int32)\n",
    "membership = Feature(shape=(None,), dtype=tf.int32)\n",
    "\n",
    "deg_adjs = []\n",
    "for i in range(0, 10 + 1):\n",
    "    deg_adj = Feature(shape=(None, i + 1), dtype=tf.int32)\n",
    "    deg_adjs.append(deg_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "gc1 = GraphConv(64,activation_fn=tf.nn.relu,in_layers=[atom_features, degree_slice, membership] + deg_adjs)\n",
    "batch_norm1 = BatchNorm(in_layers=[gc1])\n",
    "gp1 = GraphPool(in_layers=[batch_norm1, degree_slice, membership] + deg_adjs)\n",
    "\n",
    "gc2 = GraphConv(64,activation_fn=tf.nn.relu,in_layers=[gp1, degree_slice, membership] + deg_adjs)\n",
    "batch_norm2 = BatchNorm(in_layers=[gc2])\n",
    "gp2 = GraphPool(in_layers=[batch_norm2, degree_slice, membership] + deg_adjs)\n",
    "    \n",
    "dense = Dense(out_channels=128, activation_fn=tf.nn.relu, in_layers=[gp2])\n",
    "batch_norm3 = BatchNorm(in_layers=[dense])\n",
    "\n",
    "readout = GraphGather(batch_size=batch_size,activation_fn=tf.nn.tanh,in_layers=[batch_norm3, degree_slice, membership] + deg_adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.layers import Dense, SoftMax, \\\n",
    "    SoftMaxCrossEntropy, WeightedError, Stack\n",
    "from deepchem.models.tensorgraph.layers import Label, Weights\n",
    "\n",
    "costs = []\n",
    "labels = []\n",
    "for task in range(len(sider_tasks)):\n",
    "    classification = Dense(out_channels=2, activation_fn=None, in_layers=[readout])\n",
    "\n",
    "    softmax = SoftMax(in_layers=[classification])\n",
    "    tg.add_output(softmax)\n",
    "\n",
    "    label = Label(shape=(None, 2))\n",
    "    labels.append(label)\n",
    "    cost = SoftMaxCrossEntropy(in_layers=[label, classification])\n",
    "    costs.append(cost)\n",
    "    \n",
    "all_cost = Stack(in_layers=costs, axis=1)\n",
    "weights = Weights(shape=(None, len(sider_tasks)))\n",
    "loss = WeightedError(in_layers=[all_cost, weights])\n",
    "tg.set_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "def data_generator(dataset, epochs=1, predict=False, pad_batches=True):\n",
    "    for epoch in range(epochs):\n",
    "        if not predict:\n",
    "            print('Starting epoch %i' % epoch)\n",
    "        for ind, (X_b, y_b, w_b, ids_b) in enumerate(\n",
    "            dataset.iterbatches(batch_size, pad_batches=pad_batches, deterministic=True)):\n",
    "            d = {}\n",
    "\n",
    "            for index, label in enumerate(labels):\n",
    "                d[label] = to_one_hot(y_b[:, index])\n",
    "            d[weights] = w_b\n",
    "            multiConvMol = ConvMol.agglomerate_mols(X_b)\n",
    "            d[atom_features] = multiConvMol.get_atom_features()\n",
    "            d[degree_slice] = multiConvMol.deg_slice\n",
    "            d[membership] = multiConvMol.membership\n",
    "            for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "                d[deg_adjs[i - 1]] = multiConvMol.get_deg_adjacency_lists()[i]\n",
    "            yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "772.023229184358"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Epochs set to 1 to render tutorials online.\n",
    "# Set epochs=10 for better results.\n",
    "tg.fit_generator(data_generator(train_dataset, epochs=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.7551601971657425, 0.6855652250805043, 0.9932451449479313, 0.6951993619363386, 0.7224235807860262, 0.727182978970521, 0.7951928110277439, 0.7507341314660041, 0.68026188354705, 0.7510888019487709, 0.7108322221350694, 0.7084044520304389, 0.7479141935864084, 0.743953132359868, 0.6914698982872773, 0.7473882489078427, 0.762614282184334, 0.7114269928173188, 0.6658647570027227, 0.6770689306650496, 0.7146019724046404, 0.7004771278902939, 0.8067475638904211, 0.6684436149965817, 0.7106851729455828, 0.8235745614035088, 0.6718711147948612]\n",
      "----------------\n",
      "Training ROC-AUC Score: 0.734052\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(\n",
    "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
    "\n",
    "def reshape_y_pred(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    TensorGraph.Predict returns a list of arrays, one for each output\n",
    "    We also have to remove the padding on the last batch\n",
    "    Metrics taks results of shape (samples, n_task, prob_of_class)\n",
    "    \"\"\"\n",
    "    n_samples = len(y_true)\n",
    "    retval = np.stack(y_pred, axis=1)\n",
    "    return retval[:n_samples]\n",
    "\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_predictions = tg.predict_on_generator(data_generator(train_dataset, predict=True))\n",
    "train_predictions = reshape_y_pred(train_dataset.y, train_predictions)\n",
    "train_scores = metric.compute_metric(train_dataset.y, train_predictions, train_dataset.w)\n",
    "\n",
    "print(\"----------------\")\n",
    "print(\"Training ROC-AUC Score: %f\" % train_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.6748417721518988, 0.5363036303630363, 0.7253521126760563, 0.5841663334666134, 0.6705484598046582, 0.5010025062656642, 0.6146179401993355, 0.6518644067796611, 0.5839982269503545, 0.6334120425029516, 0.6005067567567568, 0.5020661157024793, 0.592436974789916, 0.5939024390243903, 0.5728613569321535, 0.6557597489914837, 0.6176181102362205, 0.6124121779859484, 0.6255813953488372, 0.595250944414463, 0.5946511627906976, 0.6615284411636996, 0.6590330788804071, 0.5359037127702977, 0.6295383236216943, 0.7131043256997456, 0.5598891730605285]\n",
      "Valid ROC-AUC Score: 0.611043\n"
     ]
    }
   ],
   "source": [
    "valid_predictions = tg.predict_on_generator(data_generator(valid_dataset, predict=True))\n",
    "valid_predictions = reshape_y_pred(valid_dataset.y, valid_predictions)\n",
    "valid_scores = metric.compute_metric(valid_dataset.y, valid_predictions, valid_dataset.w)\n",
    "print(\"Valid ROC-AUC Score: %f\" % valid_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.6493275316455696, 0.5961743393009378, 0.5283687943262412, 0.5894117647058823, 0.6663641863278887, 0.6321995464852609, 0.718011811023622, 0.542016806722689, 0.6634920634920635, 0.5993740219092332, 0.5237919132149902, 0.6000000000000001, 0.66, 0.42530345471521946, 0.6395568128241396, 0.5571025020177562, 0.6321195144724556, 0.638188608776844, 0.6961436170212767, 0.6845827439886846, 0.5972644376899696, 0.6195430436556507, 0.46111111111111114, 0.5506456820016142, 0.5884696016771489, 0.6979166666666667, 0.6515957446808511]\n",
      "Valid ROC-AUC Score: 0.607707\n"
     ]
    }
   ],
   "source": [
    "test_predictions = tg.predict_on_generator(data_generator(test_dataset, predict=True))\n",
    "test_predictions = reshape_y_pred(test_dataset.y, test_predictions)\n",
    "test_scores = metric.compute_metric(test_dataset.y, test_predictions, test_dataset.w)\n",
    "print(\"Valid ROC-AUC Score: %f\" % test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Comparision of Results with MoleculeNet results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
