{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OFFSIDES dataset loader.\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import deepchem\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def load_offsides(featurizer='ECFP', split='index', reload=True, K=4):\n",
    "  logger.info(\"About to load ofssides dataset.\")\n",
    "  data_dir = deepchem.utils.get_data_dir()\n",
    "  if reload:\n",
    "    save_dir = os.path.join(data_dir, \"offsides/\" + featurizer + \"/\" + str(split))\n",
    "\n",
    "  dataset_file = os.path.join(\"/home/mamonteiro/source-code/Project-LEI/offsides/\", \"offsides.csv.gz\")\n",
    "\n",
    "\n",
    "  dataset = deepchem.utils.save.load_from_disk(dataset_file)\n",
    "  logger.info(\"Columns of dataset: %s\" % str(dataset.columns.values))\n",
    "  logger.info(\"Number of examples in dataset: %s\" % str(dataset.shape[0]))\n",
    "  OFFSIDES_tasks = dataset.columns.values[1:].tolist()\n",
    "\n",
    "  if reload:\n",
    "    loaded, all_dataset, transformers = deepchem.utils.save.load_dataset_from_disk(\n",
    "        save_dir)\n",
    "    if loaded:\n",
    "      return OFFSIDES_tasks, all_dataset, transformers\n",
    "\n",
    "  # Featurize OFFSIDES dataset\n",
    "  logger.info(\"About to featurize OFFSIDES dataset.\")\n",
    "  if featurizer == 'ECFP':\n",
    "    featurizer = deepchem.feat.CircularFingerprint(size=1024)\n",
    "  elif featurizer == 'GraphConv':\n",
    "    featurizer = deepchem.feat.ConvMolFeaturizer()\n",
    "  elif featurizer == 'Weave':\n",
    "    featurizer = deepchem.feat.WeaveFeaturizer()\n",
    "  elif featurizer == 'Raw':\n",
    "    featurizer = deepchem.feat.RawFeaturizer()\n",
    "\n",
    "  logger.info(\"OFFSIDES tasks: %s\" % str(OFFSIDES_tasks))\n",
    "  logger.info(\"%d tasks in total\" % len(OFFSIDES_tasks))\n",
    "\n",
    "  loader = deepchem.data.CSVLoader(\n",
    "      tasks=OFFSIDES_tasks, smiles_field=\"smiles\", featurizer=featurizer)\n",
    "  dataset = loader.featurize(dataset_file)\n",
    "  logger.info(\"%d datapoints in OFFSIDES dataset\" % len(dataset))\n",
    "\n",
    "  # Initialize transformers\n",
    "  transformers = [\n",
    "      deepchem.trans.BalancingTransformer(transform_w=True, dataset=dataset)\n",
    "  ]\n",
    "  logger.info(\"About to transform data\")\n",
    "  for transformer in transformers:\n",
    "    dataset = transformer.transform(dataset)\n",
    "\n",
    "  if split == None:\n",
    "    return OFFSIDES_tasks, (dataset, None, None), transformers\n",
    "\n",
    "  splitters = {\n",
    "      'index': deepchem.splits.IndexSplitter(),\n",
    "      'random': deepchem.splits.RandomSplitter(),\n",
    "      'scaffold': deepchem.splits.ScaffoldSplitter(),\n",
    "      'task': deepchem.splits.TaskSplitter()\n",
    "  }\n",
    "  splitter = splitters[split]\n",
    "  if split == 'task':\n",
    "    fold_datasets = splitter.k_fold_split(dataset, K)\n",
    "    all_dataset = fold_datasets\n",
    "  else:\n",
    "    train, valid, test = splitter.train_valid_test_split(dataset)\n",
    "    if reload:\n",
    "      deepchem.utils.save.save_dataset_to_disk(save_dir, train, valid, test,\n",
    "                                               transformers)\n",
    "    all_dataset = (train, valid, test)\n",
    "  return OFFSIDES_tasks, all_dataset, transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "offsides_tasks, offsides_datasets, transformers = load_offsides(featurizer='GraphConv',reload=True)\n",
    "train_dataset, valid_dataset, test_dataset = offsides_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.CircularFingerprint(size = 704)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dc.data.CSVLoader(\n",
    "      tasks=offsides_tasks, smiles_field=\"smiles\",\n",
    "      featurizer=featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from offsides.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "TIMING: featurizing shard 0 took 0.936 s\n",
      "TIMING: dataset construction took 0.964 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "dataset = loader.featurize('offsides.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing train/valid/test indices\n",
      "TIMING: dataset construction took 0.063 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.015 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.014 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "splitter = dc.splits.RandomSplitter('offsides.csv')\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(\n",
    "    dataset)\n",
    "#NOTE THE RENAMING:\n",
    "valid_dataset, test_dataset = test_dataset, valid_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = train_dataset.y.shape[0]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\"activation\": [\"relu\",\"sigmoid\",\"tahn\"],\n",
    "               \"optimizer\": [\"Adam\",\"RMSprop\"],\n",
    "               \"momentum\": [.9],\n",
    "               \"penalty\": [0.]\n",
    "              }\n",
    "n_features = train_dataset.y.shape[0]\n",
    "def model_builder(model_params, model_dir):\n",
    "    model = dc.models.MultitaskClassifier(\n",
    "    len(offsides_tasks), n_features, **model_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1/6\n",
      "hyperparameters: {'activation': 'relu', 'optimizer': 'Adam', 'momentum': 0.9, 'penalty': 0.0}\n",
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.5607876712328768, 0.6791497975708503, 0.3970588235294118, 0.46087636932707354, 0.6721518987341772, 0.5830687830687831, 0.7037037037037037, 0.5404761904761904, 0.5377551020408163, 0.4324009324009324, 0.748995983935743, 0.40588235294117647, 0.2852941176470588, 0.5240506329113925, 0.3827160493827161, 0.43478260869565216, 0.5542857142857143, 0.625, 0.41049382716049376, 0.5604575163398693, 0.6375939849624059, 0.6309931506849316, 0.5562770562770563, 0.6218708827404479, 0.6781376518218624, 0.7943722943722944, 0.5884615384615384]\n",
      "Model 1/6, Metric mean-roc_auc_score, Validation set 0: 0.555818\n",
      "\tbest_validation_score so far: 0.555818\n",
      "Fitting model 2/6\n",
      "hyperparameters: {'activation': 'relu', 'optimizer': 'RMSprop', 'momentum': 0.9, 'penalty': 0.0}\n",
      "computed_metrics: [0.485445205479452, 0.6720647773279352, 0.42238562091503273, 0.4663536776212832, 0.6278481012658228, 0.5857142857142859, 0.712962962962963, 0.7214285714285715, 0.4780612244897959, 0.43123543123543123, 0.6385542168674698, 0.4411764705882353, 0.3764705882352941, 0.5936708860759494, 0.5108024691358024, 0.45586297760210803, 0.5771428571428572, 0.6049382716049383, 0.38117283950617287, 0.5343137254901962, 0.6917293233082706, 0.6113013698630136, 0.5622294372294372, 0.6060606060606061, 0.6923076923076923, 0.7781385281385281, 0.5833333333333334]\n",
      "Model 2/6, Metric mean-roc_auc_score, Validation set 1: 0.564545\n",
      "\tbest_validation_score so far: 0.564545\n",
      "Fitting model 3/6\n",
      "hyperparameters: {'activation': 'sigmoid', 'optimizer': 'Adam', 'momentum': 0.9, 'penalty': 0.0}\n",
      "computed_metrics: [0.5299657534246576, 0.6690283400809717, 0.39950980392156865, 0.45774647887323944, 0.6518987341772152, 0.5931216931216932, 0.6712962962962963, 0.6619047619047619, 0.5030612244897958, 0.48717948717948717, 0.6546184738955824, 0.5382352941176471, 0.32647058823529407, 0.610126582278481, 0.3935185185185185, 0.45256916996047436, 0.5504761904761905, 0.5555555555555556, 0.37808641975308643, 0.5302287581699346, 0.6781954887218045, 0.6130136986301371, 0.5616883116883117, 0.6403162055335968, 0.7378542510121457, 0.7640692640692641, 0.6051282051282052]\n",
      "Model 3/6, Metric mean-roc_auc_score, Validation set 2: 0.563513\n",
      "\tbest_validation_score so far: 0.564545\n",
      "Fitting model 4/6\n",
      "hyperparameters: {'activation': 'sigmoid', 'optimizer': 'RMSprop', 'momentum': 0.9, 'penalty': 0.0}\n",
      "computed_metrics: [0.5222602739726028, 0.6983805668016194, 0.4052287581699347, 0.4522691705790297, 0.6354430379746836, 0.5830687830687831, 0.646604938271605, 0.5404761904761904, 0.47959183673469385, 0.4545454545454546, 0.751004016064257, 0.42647058823529416, 0.3411764705882353, 0.5468354430379747, 0.43672839506172845, 0.44202898550724634, 0.5657142857142858, 0.6033950617283951, 0.4598765432098766, 0.5294117647058824, 0.6812030075187969, 0.6404109589041096, 0.5438311688311688, 0.6587615283267456, 0.6497975708502024, 0.7662337662337662, 0.6173076923076923]\n",
      "Model 4/6, Metric mean-roc_auc_score, Validation set 3: 0.558447\n",
      "\tbest_validation_score so far: 0.564545\n",
      "Fitting model 5/6\n",
      "hyperparameters: {'activation': 'tahn', 'optimizer': 'Adam', 'momentum': 0.9, 'penalty': 0.0}\n",
      "computed_metrics: [0.5188356164383561, 0.6831983805668016, 0.37254901960784315, 0.4702660406885759, 0.6354430379746836, 0.5571428571428572, 0.712962962962963, 0.6333333333333333, 0.513265306122449, 0.46153846153846156, 0.6666666666666666, 0.47352941176470587, 0.23823529411764705, 0.5620253164556962, 0.3873456790123457, 0.4413702239789196, 0.520952380952381, 0.5339506172839505, 0.4027777777777778, 0.5571895424836601, 0.6669172932330827, 0.6267123287671232, 0.538961038961039, 0.63965744400527, 0.6275303643724697, 0.75, 0.6102564102564103]\n",
      "Model 5/6, Metric mean-roc_auc_score, Validation set 4: 0.548245\n",
      "\tbest_validation_score so far: 0.564545\n",
      "Fitting model 6/6\n",
      "hyperparameters: {'activation': 'tahn', 'optimizer': 'RMSprop', 'momentum': 0.9, 'penalty': 0.0}\n",
      "computed_metrics: [0.553082191780822, 0.6751012145748987, 0.40522875816993464, 0.46322378716744916, 0.610126582278481, 0.5650793650793651, 0.6882716049382716, 0.6357142857142857, 0.4892857142857143, 0.48484848484848486, 0.7028112449799198, 0.5058823529411764, 0.25, 0.5569620253164558, 0.44135802469135804, 0.4367588932806324, 0.579047619047619, 0.6188271604938271, 0.39043209876543206, 0.5718954248366013, 0.6736842105263158, 0.5907534246575342, 0.5660173160173161, 0.592885375494071, 0.6953441295546559, 0.7673160173160173, 0.6006410256410257]\n",
      "Model 6/6, Metric mean-roc_auc_score, Validation set 5: 0.559651\n",
      "\tbest_validation_score so far: 0.564545\n",
      "computed_metrics: [0.9632423291725074, 0.9550379099296611, 0.9289761937316743, 0.9166351829988194, 0.9579016905383899, 0.8899065370504271, 0.9528573771644133, 0.908457087080806, 0.8825625080969037, 0.9598475890158981, 0.9567343502056413, 0.9550424399366997, 0.96247667288723, 0.9630913687251714, 0.9583650914634146, 0.8978879706152433, 0.9452123397435896, 0.9330136030694105, 0.9656967948492419, 0.9392598097022762, 0.926435192297844, 0.9207740106177607, 0.9014257406601904, 0.9274517083218567, 0.9403364190562205, 0.9581298828125, 0.9268987062721238]\n",
      "Best hyperparameters: ('relu', 'RMSprop', 0.9, 0.0)\n",
      "train_score: 0.936802\n",
      "validation_score: 0.564545\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
    "optimizer = dc.hyper.HyperparamOpt(model_builder)\n",
    "best_dnn, best_hyperparams, all_results = optimizer.hyperparam_search(params_dict, train_dataset, valid_dataset, [], metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultitaskClassifier(activation_fns=None, bias_init_consts=None, dropouts=None,\n",
       "                    layer_sizes=None, n_classes=2, n_features=704, n_tasks=27,\n",
       "                    weight_decay_penalty=None, weight_decay_penalty_type=None,\n",
       "                    weight_init_stddevs=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('relu', 'RMSprop', 0.9, 0.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('relu', 'Adam', 0.9, 0.0)\": 0.5558183198038952,\n",
       " \"('relu', 'RMSprop', 0.9, 0.0)\": 0.5645446463307585,\n",
       " \"('sigmoid', 'Adam', 0.9, 0.0)\": 0.5635134647857006,\n",
       " \"('sigmoid', 'RMSprop', 0.9, 0.0)\": 0.5584465280526021,\n",
       " \"('tahn', 'Adam', 0.9, 0.0)\": 0.5482449187579804,\n",
       " \"('tahn', 'RMSprop', 0.9, 0.0)\": 0.5596510493480616}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_builder(params_dict,params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375.54270987957716"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=best_dnn.fit(train_dataset,**params_dict,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.9998442471575106, 0.999908650771901, 0.9998328851617215, 0.9991499409681228, 0.9999399453502688, 0.9999107326174088, 0.9991564938260035, 0.9992330753677752, 0.9984292006736624, 1.0, 0.999935231063182, 0.9999640339519493, 0.9994001599573448, 0.9998314674371012, 1.0, 0.9997873471557681, 0.9992788461538462, 0.9999825601674224, 0.9997537205784048, 0.9997415311051161, 0.9998975777129103, 0.9996078667953667, 0.9999226716930065, 0.9996167802354406, 0.9997930307819674, 0.9999267578125, 0.99972286257763]\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(train_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.553082191780822, 0.5850202429149798, 0.38398692810457513, 0.41705790297339596, 0.6784810126582279, 0.42275132275132277, 0.6049382716049383, 0.6857142857142857, 0.5321428571428571, 0.4606643356643356, 0.5582329317269077, 0.4294117647058824, 0.20294117647058824, 0.5075949367088608, 0.49691358024691357, 0.43412384716732544, 0.6000000000000001, 0.46604938271604934, 0.48649691358024694, 0.40604575163398693, 0.5887218045112781, 0.4794520547945206, 0.5124458874458875, 0.5513833992094861, 0.5313765182186234, 0.7012987012987013, 0.5448717948717949]\n"
     ]
    }
   ],
   "source": [
    "valid_scores = model.evaluate(valid_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.5753846153846154, 0.6538734896943852, 0.6461538461538461, 0.49934895833333337, 0.8371794871794871, 0.4908045977011495, 0.5674358974358975, 0.6321138211382114, 0.45682888540031397, 0.7341772151898733, 0.5426829268292683, 0.8353658536585366, 0.6674698795180722, 0.6646341463414634, 0.7123287671232876, 0.6854887674559805, 0.5706349206349206, 0.5989583333333334, 0.7076923076923077, 0.6142857142857143, 0.6119791666666666, 0.6803966437833715, 0.6153846153846154, 0.6414392059553351, 0.6986301369863014, 0.6469760900140646, 0.620137299771167]\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(test_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean-roc_auc_score': 0.9996876895212344}\n",
      "{'mean-roc_auc_score': 0.5118962887635851}\n",
      "{'mean-roc_auc_score': 0.637325392186871}\n"
     ]
    }
   ],
   "source": [
    "print(train_scores)\n",
    "print(valid_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
