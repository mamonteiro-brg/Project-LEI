{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Convolutions For SIDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Featurization=ConvMolFeaturizer\n",
    "\n",
    "É utilizado com modelos GraphConvModel.\n",
    "\n",
    "Alternativamente, também implementamos este modelo (GraphConvModel) usando layers do TensorGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc\n",
    "from deepchem.models.tensorgraph.models.graph_models import GraphConvModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SIDER Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "All MoleculeNet datasets are split into training, validation and test subsets following a 80/10/10 ratio. \n",
    "\n",
    "Different  splittings are recommended depending on each dataset's contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "sider_tasks, sider_datasets, transformers = dc.molnet.load_sider(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = sider_datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Different classification and regress metrics are recommended based on previous works and dataset's contents:\n",
    "          ROC-AUC:  Area Under Curve of Receiver Operating Characteristics\n",
    "          PRC-AUC:  Area Under Curve of Precision Recall Curve\n",
    "          RMSE: Root-Mean-Square Error\n",
    "          MAE: Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei_deepchem_python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei_deepchem_python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/mamonteiro/anaconda3/envs/lei_deepchem_python36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamonteiro/anaconda3/envs/lei_deepchem_python36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 764.077825\n",
      "Epoch 1 loss: 657.819540\n",
      "Epoch 2 loss: 571.244958\n",
      "Epoch 3 loss: 491.105634\n",
      "Epoch 4 loss: 412.211737\n",
      "Epoch 5 loss: 366.232112\n",
      "Epoch 6 loss: 318.701240\n",
      "Epoch 7 loss: 278.768892\n",
      "Epoch 8 loss: 236.300197\n",
      "Epoch 9 loss: 221.093931\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "losses = []\n",
    "\n",
    "model = GraphConvModel(\n",
    "    len(sider_tasks), batch_size=50, mode='classification')\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # Set nb_epoch=10 for better results.\n",
    "    loss = model.fit(train_dataset, nb_epoch=num_epochs)\n",
    "    print(\"Epoch %d loss: %f\" % (i, loss))\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/home/mamonteiro/anaconda3/envs/lei_deepchem_python36/lib/python3.6/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "\n",
    "plot.ylabel(\"Loss\")\n",
    "plot.xlabel(\"Epoch\")\n",
    "x = range(num_epochs)\n",
    "y = losses\n",
    "plot.scatter(x, y)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.9819531731361676, 0.9513400193062995, 0.9999061825687212, 0.9692734115972026, 0.9719674915089763, 0.9593456688855174, 0.9796574187169197, 0.9986857506622584, 0.9267152210126681, 0.9800017223985631, 0.9960153737548043, 0.9618448190029159, 0.9933363641721179, 0.9985751295336787, 0.9680415545834126, 0.9757693857915539, 0.9776748208549544, 0.9974383444673263, 0.9402558651299839, 0.9552274105518497, 0.9691706900365344, 0.9633378932968536, 0.9990163633020777, 0.9781654009374404, 0.9718403466255415, 0.9814792663476873, 0.9499205691393839]\n",
      "Training ROC-AUC Score: 0.973924\n",
      "computed_metrics: [0.7331882911392404, 0.6553512494106553, 0.8380281690140845, 0.6485405837664935, 0.6919609316303532, 0.5721804511278196, 0.6124031007751938, 0.6396610169491526, 0.5556294326241136, 0.6088154269972451, 0.5833333333333333, 0.606749311294766, 0.5714285714285715, 0.6800813008130082, 0.6209439528023599, 0.6931869116987898, 0.6796259842519685, 0.6128024980483997, 0.6325581395348838, 0.6546141392336753, 0.5595348837209302, 0.6617455492835432, 0.7372773536895674, 0.6017951856385149, 0.6996862393545495, 0.688295165394402, 0.5411338448422848]\n",
      "Validation ROC-AUC Score: 0.643724\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(\n",
    "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
    "print(\"Training ROC-AUC Score: %f\" % train_scores[\"mean-roc_auc_score\"])\n",
    "valid_scores = model.evaluate(valid_dataset, [metric], transformers)\n",
    "print(\"Validation ROC-AUC Score: %f\" % valid_scores[\"mean-roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamonteiro/anaconda3/envs/lei_deepchem_python36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "737.432861328125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphConvModel(\n",
    "    len(sider_tasks), batch_size=50, mode='classification')\n",
    "# Set nb_epoch=10 for better results.\n",
    "model.fit(train_dataset, nb_epoch=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.7716451016635859, 0.7382522640689131, 0.9956843981611784, 0.750667396133387, 0.7680422125181949, 0.7439731705369523, 0.8095591228988543, 0.7905928496621969, 0.7283926703598962, 0.777017051745774, 0.7618362224488195, 0.7512890263850367, 0.7985923437644702, 0.8046219971738107, 0.7329429666059832, 0.7817294440399418, 0.7865332344946874, 0.7462655080616807, 0.7200738502853307, 0.7309985850010108, 0.757529994127024, 0.7348503553434986, 0.860470674756389, 0.7363433667781494, 0.7578247778512153, 0.8356858054226475, 0.6881337201270893]\n",
      "Training ROC-AUC Score: 0.772576\n",
      "computed_metrics: [0.6770174050632912, 0.5056577086280056, 0.5845070422535211, 0.5969612155137944, 0.6983471074380165, 0.4972431077694236, 0.654485049833887, 0.5840677966101695, 0.5487588652482269, 0.6048799685163322, 0.6323198198198198, 0.4986225895316804, 0.5892857142857142, 0.6630081300813008, 0.5212389380530973, 0.6647243388614971, 0.6850393700787402, 0.5597189695550351, 0.6306976744186047, 0.5982191041554237, 0.594186046511628, 0.6057316543638733, 0.7690839694656488, 0.5793553651570786, 0.6461228148812191, 0.6946564885496183, 0.5837595907928389]\n",
      "Validation ROC-AUC Score: 0.609915\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(\n",
    "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
    "print(\"Training ROC-AUC Score: %f\" % train_scores[\"mean-roc_auc_score\"])\n",
    "\n",
    "valid_scores = model.evaluate(valid_dataset, [metric], transformers)\n",
    "print(\"Validation ROC-AUC Score: %f\" % valid_scores[\"mean-roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Implementation GraphConvModel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TensorGraph - Simplicity is Beauty\n",
    "TensorGraph is a simple, lean, and clean framework on TensorFlow for building any imaginable models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What’s going on under the hood? \n",
    "\n",
    "Now we will build GraphConvModel ourselves.\n",
    "\n",
    "The first step is to create a TensorGraph object. \n",
    "This object will hold the “computational graph” that defines the computation that a graph convolutional network will perform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.tensor_graph import TensorGraph\n",
    "\n",
    "tg = TensorGraph(use_queue=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.layers import Feature\n",
    "\n",
    "atom_features = Feature(shape=(None, 75))\n",
    "degree_slice = Feature(shape=(None, 2), dtype=tf.int32)\n",
    "membership = Feature(shape=(None,), dtype=tf.int32)\n",
    "\n",
    "deg_adjs = []\n",
    "for i in range(0, 10 + 1):\n",
    "    deg_adj = Feature(shape=(None, i + 1), dtype=tf.int32)\n",
    "    deg_adjs.append(deg_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.layers import Dense, GraphConv, BatchNorm\n",
    "from deepchem.models.tensorgraph.layers import GraphPool, GraphGather\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "gc1 = GraphConv(\n",
    "    64,\n",
    "    activation_fn=tf.nn.relu,\n",
    "    in_layers=[atom_features, degree_slice, membership] + deg_adjs)\n",
    "batch_norm1 = BatchNorm(in_layers=[gc1])\n",
    "gp1 = GraphPool(in_layers=[batch_norm1, degree_slice, membership] + deg_adjs)\n",
    "gc2 = GraphConv(\n",
    "    64,\n",
    "    activation_fn=tf.nn.relu,\n",
    "    in_layers=[gp1, degree_slice, membership] + deg_adjs)\n",
    "batch_norm2 = BatchNorm(in_layers=[gc2])\n",
    "gp2 = GraphPool(in_layers=[batch_norm2, degree_slice, membership] + deg_adjs)\n",
    "dense = Dense(out_channels=128, activation_fn=tf.nn.relu, in_layers=[gp2])\n",
    "batch_norm3 = BatchNorm(in_layers=[dense])\n",
    "readout = GraphGather(\n",
    "    batch_size=batch_size,\n",
    "    activation_fn=tf.nn.tanh,\n",
    "    in_layers=[batch_norm3, degree_slice, membership] + deg_adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.layers import Dense, SoftMax, \\\n",
    "    SoftMaxCrossEntropy, WeightedError, Stack\n",
    "from deepchem.models.tensorgraph.layers import Label, Weights\n",
    "\n",
    "costs = []\n",
    "labels = []\n",
    "for task in range(len(sider_tasks)):\n",
    "    classification = Dense(\n",
    "        out_channels=2, activation_fn=None, in_layers=[readout])\n",
    "\n",
    "    softmax = SoftMax(in_layers=[classification])\n",
    "    tg.add_output(softmax)\n",
    "\n",
    "    label = Label(shape=(None, 2))\n",
    "    labels.append(label)\n",
    "    cost = SoftMaxCrossEntropy(in_layers=[label, classification])\n",
    "    costs.append(cost)\n",
    "all_cost = Stack(in_layers=costs, axis=1)\n",
    "weights = Weights(shape=(None, len(sider_tasks)))\n",
    "loss = WeightedError(in_layers=[all_cost, weights])\n",
    "tg.set_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "def data_generator(dataset, epochs=1, predict=False, pad_batches=True):\n",
    "  for epoch in range(epochs):\n",
    "    if not predict:\n",
    "        print('Starting epoch %i' % epoch)\n",
    "    for ind, (X_b, y_b, w_b, ids_b) in enumerate(\n",
    "        dataset.iterbatches(\n",
    "            batch_size, pad_batches=pad_batches, deterministic=True)):\n",
    "      d = {}\n",
    "      for index, label in enumerate(labels):\n",
    "        d[label] = to_one_hot(y_b[:, index])\n",
    "      d[weights] = w_b\n",
    "      multiConvMol = ConvMol.agglomerate_mols(X_b)\n",
    "      d[atom_features] = multiConvMol.get_atom_features()\n",
    "      d[degree_slice] = multiConvMol.deg_slice\n",
    "      d[membership] = multiConvMol.membership\n",
    "      for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        d[deg_adjs[i - 1]] = multiConvMol.get_deg_adjacency_lists()[i]\n",
    "      yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "804.3340825619905"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Epochs set to 1 to render tutorials online.\n",
    "# Set epochs=10 for better results.\n",
    "tg.fit_generator(data_generator(train_dataset, epochs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "633.0344035273013"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Epochs set to 1 to render tutorials online.\n",
    "# Set epochs=10 for better results.\n",
    "tg.fit_generator(data_generator(train_dataset, epochs=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.8175569932224276, 0.7561805949582556, 0.9984520123839009, 0.7817598164907817, 0.8211572052401745, 0.7765590632916906, 0.8505254076271351, 0.8735137688153274, 0.7592724596133731, 0.8393248197632932, 0.8356106361283238, 0.8128600384040964, 0.8627030030560958, 0.8906735751295336, 0.7888034489941943, 0.8240212840649053, 0.8436743266617246, 0.8341252699784016, 0.7668606169109693, 0.7709015564988883, 0.7984005674667642, 0.7880551199492842, 0.9359808788380217, 0.7942366205337621, 0.7990957993684364, 0.8766547049441786, 0.7520652023760188]\n",
      "Training ROC-AUC Score: 0.824038\n",
      "computed_metrics: [0.7227056962025316, 0.607967939651108, 0.5633802816901409, 0.6379448220711714, 0.7141247182569497, 0.5453634085213033, 0.6943521594684385, 0.6261016949152542, 0.5673758865248227, 0.613931523022432, 0.606418918918919, 0.5426997245179063, 0.5458683473389356, 0.6028455284552845, 0.5884955752212389, 0.6857911250560287, 0.6840551181102362, 0.6311475409836065, 0.6127906976744186, 0.6165677280086346, 0.5925581395348837, 0.616804168475901, 0.720737913486005, 0.5932272541819665, 0.6804123711340206, 0.7608142493638677, 0.526001705029838]\n",
      "Valid ROC-AUC Score: 0.625944\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(\n",
    "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
    "\n",
    "def reshape_y_pred(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    TensorGraph.Predict returns a list of arrays, one for each output\n",
    "    We also have to remove the padding on the last batch\n",
    "    Metrics taks results of shape (samples, n_task, prob_of_class)\n",
    "    \"\"\"\n",
    "    n_samples = len(y_true)\n",
    "    retval = np.stack(y_pred, axis=1)\n",
    "    return retval[:n_samples]\n",
    "\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_predictions = tg.predict_on_generator(data_generator(train_dataset, predict=True))\n",
    "train_predictions = reshape_y_pred(train_dataset.y, train_predictions)\n",
    "train_scores = metric.compute_metric(train_dataset.y, train_predictions, train_dataset.w)\n",
    "print(\"Training ROC-AUC Score: %f\" % train_scores)\n",
    "\n",
    "valid_predictions = tg.predict_on_generator(data_generator(valid_dataset, predict=True))\n",
    "valid_predictions = reshape_y_pred(valid_dataset.y, valid_predictions)\n",
    "valid_scores = metric.compute_metric(valid_dataset.y, valid_predictions, valid_dataset.w)\n",
    "print(\"Valid ROC-AUC Score: %f\" % valid_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Comparision of Results with MoleculeNet results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
